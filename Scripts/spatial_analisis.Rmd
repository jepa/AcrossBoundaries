---
title: "Spatial Analysis"
output: 
 # html_document
  html_notebook:
  fig_width: 6
  fig_height: 4
  toc: false
  toc_depth: 3
  code_folding: hide
  toc_float:
    collapsed: false
---

```{r setup, include=FALSE}
library(MyFunctions)
MyFunctions::my_lib(c("ggmap","sf","tidyverse","tools","readr","data.table","maps","viridis","wesanderson","knitr","kableExtra","plotly"))
```


# Load data

## Maps data

We use three different shapefiles for the continental U.S. land mass, the State waters of maine, new hampshire, massachusets, connecticut, rhode island, new york, new jersey, delaware, maryland, virginia, north carolina and the North East EEZ.

1.- **Land shapefile;** covers the US land territory for visualization. Data provided from the `map` package.

2.- **State waters;** covers the state waters of the NE US states. Data from [data.gov](https://catalog.data.gov/dataset/federal-and-state-waters).  

*License: No license information was provided. If this work was prepared by an officer or employee of the United States government as part of that person's official duties it is considered a U.S. Government Work.*

3.- **EEZ shapefile;** Used the *Sea Around Us* shapefle updated to June 2016.

```{r maps_sf, eval = T, echo = T, results = 'hide'}

States <- c("maine", "new hampshire", "massachusetts", "connecticut", "rhode island", "new york", "new jersey", "delaware", "maryland", "virginia", "north carolina","pennsylvania") 

# US State Map (land)

land_sf <- st_as_sf(map("state", plot = FALSE, fill = TRUE)) %>% 
  filter(ID %in% States) 

# ggplot(us_map) +
  # geom_sf()

# US EEZ map

# path_world <- MyFunctions::my_path("G", extra_path = "Spatial/SAU/SAU_Shapefile")
path_world <- "~/Downloads/SAU_Shapefile"

# The File
fnam_world <- "SAUEEZ_July2015.shp"

# Load it!
eez_sf <- st_read(dsn = path_world,
                        layer =file_path_sans_ext(fnam_world)) %>% 
  rename(eez_name = Name) %>% 
  st_transform(crs = 4326) %>% # 4326
  st_simplify(preserveTopology = TRUE, dTolerance = 10000) %>% #0.1 for paper
  filter(eez_name == "USA (East Coast)")


# ggplot(eez_sf) +
# geom_sf(aes(),fill =NA)

# ggplot() +
#   geom_sf(data = World_eez_sf, aes(), color = "red") +
#   geom_sf(data = us_map, aes(), color = "blue")

# US state waters
# https://catalog.data.gov/dataset/federal-and-state-waters

# us_state_w <- rgdal::readOGR(dsn = "~/Downloads/FederalAndStateWaters/FederalAndStateWaters.gdb")
state_sf <-  st_read("~/Downloads/FederalAndStateWaters/FederalAndStateWaters.gdb") %>%
  janitor::clean_names() %>% 
  mutate(jurisdicti = str_to_lower(jurisdicti)) %>% 
  filter(jurisdicti %in% States) %>% 
  rename(state = jurisdicti) %>% 
  # st_transform(crs = 4326)  # for matching projections
  st_simplify(preserveTopology = TRUE, dTolerance = 10000) #0.1 for paper


grid_sf <-  st_read("/Volumes/Enterprise/Data/AcrossBoundaries/Data/Spatial/grid_sf/grid_eez_sf.shp")

unique(land_sf$ID)

```


## Spatial component

### Create base shapefile for computation

As a first step we need to divide the NE US EEZ among the different states. For that we expanded state waters up to the 200 nautical miles to then estimate the percentage that each expanded-state-waters occupied. Note that in all cases these areas overlapped and percentages accounted for it. We did this by following these steps:

- 1. Expand state waters using a buffer

- 2. Grid that buffer on a 0.3 resolution

- 3. Crop the buffer to the EEZ

#### 1. Expand Spatial regions (a.k.a  buffers)

We set a buffer of *410000* m (410 km, ~ 221 nm) that overshoots the EEZ a bit, but is eventually cropped

```{r buffer, eval = T, echo = T}

# Buffer state waters
state_bf = st_buffer(state_sf, 410000) %>% 
  st_transform(4326) %>% # to match shape
  st_set_crs(4326)

# ------------------------------ #
# Testing and visualizing the buffer 
# ------------------------------ #

state_bf_plot <- ggplot() +
  geom_sf(data = eez_sf, aes(), fill = NA) +
  geom_sf(data = state_bf, aes(color = state), fill = NA)
#   

# ggsave("../Results/Partial/state_waters_buffer.png",state_bf_plot)

# ------------------------------ #

state_bf_plot

```

#### 2. Expand grid within buffer

Here we expand a grid within the buffer so we can estimate the proportion of each state

```{r grid_indexing, eval = T, echo = T, message = F, warning = F}

# Create grid of the region
bbox <- c(st_bbox(state_bf))

# Expand the grid
ne_grid <- expand.grid(
    lon = seq(from = bbox["xmin"], to = bbox["xmax"], by = 0.3),
    lat = seq(from = bbox["ymin"], to = bbox["ymax"], by = 0.3)
) %>% 
  rowid_to_column("index")

# ----------- #
# [TEST] Plot all layers
# ----------- #

# Looks good
state_sf %>%
  st_transform(4326) %>% # to match shape
  st_set_crs(4326) %>%
  st_simplify(preserveTopology = TRUE, dTolerance = 10000) %>%
  ggplot() +
  geom_sf(aes(color = state))+
  # geom_sf(data = eez_sf, aes(),fill =NA) +
  # ggplot()+
  geom_tile(data = ne_grid,
            aes(
              x = lon,
              y = lat
            ),
            alpha = 0.2
  ) 


```

##### 2.1 Merge grid and buffers

Once we have a gridded area, we converted the grid to a `sf` so we can merge it with the buffered states and finally filter out everything outside the states polygon

```{r grid_buf_merge, eval = T, echo = T, message = F, warning = F, fig.width = 10}

# ---------------- #
# Convert grid to sf
# ---------------- #
grid_sf <- st_as_sf(ne_grid,
             coords = c("lon", "lat"),
             crs = 4326) %>% 
  st_join(state_bf) %>% 
  filter(!is.na(state))

# Create data frame for future computations
# Note, will be used in next chunk
grid_bf_dt <- as.data.frame(grid_sf) %>%
    select(index,state)
    # group_by(state) %>% 
    # summarise(length(index))


# ---------------- #
# [TEST] 
# Visualization of grid
# ---------------- #

gridExtra::grid.arrange(
  # Overall (overlapping) position
  ggplot(grid_sf) +
    geom_sf(aes(color = state), alpha = 0.3) +
    geom_sf(data = eez_sf, aes(),fill =NA) + 
    theme(legend.position = ""),
  # Showing each state separatley
  ggplot() +
    geom_sf(data = grid_sf, aes(color = state),size = 0.1, alpha = 0.3) +
    facet_wrap(~state) +
    theme(legend.position = "top"),
  nrow = 1)

```

#### 3. Crop buffers to EEZ

Finally, we crop the grided buffers to within the EEZ to capture the actual water space.

*Note:* This step takes quite a while because of the size of the EEZ shapefile. No, you cannot use `st_simplify()` here

```{r buff_to_eez, eval =T, echo = T, message = F, warning = F}


# I don't know how to undo st_simplify so need to re-load the shapefile
eez_sf <- st_read(dsn = path_world,
                        layer =file_path_sans_ext(fnam_world)) %>% 
  rename(eez_name = Name) %>% 
  st_transform(crs = 4326) %>% # 4326
  filter(eez_name == "USA (East Coast)")

# Get the overlapping segments
grid_eez_sf <- st_intersection(grid_sf,eez_sf)

# write_sf(grid_eez_sf, paste0(my_path("D", "Spatial"),"grid_eez_sf.shp"))

# Get final df with index
grid_eez_df <- as.data.frame(grid_eez_sf) %>%
  select(state,index) %>% 
  left_join(ne_grid, 
            by = "index")

# write_csv(grid_eez_df, paste0(my_path("R", "Partial"),"grid_eez_df.csv"))

# Plot to make sure makes sense (Picasso syle)
grid_eez_sf %>%
  st_simplify(preserveTopology = TRUE, dTolerance = 10000) %>% #0.1 for paper
  ggplot() +
  geom_sf(aes(color = state), alpha = 0.3)

```

## Interpolation rutine

Here we [interpolate](https://swilke-geoscience.net/post/spatial_interpolation/) the survey data within the previously created grid.

- We removed cases where `wtcpue < 0`

### Function for interpolation

This is the main function used to interpolate the data per year. It follows a Triangular Irregular Surface method using the `interp::interp()` function.

```{r interpol_function, eval = T, echo = T}

tis <- function(input_data, grid, yr, taxa, reg){
  
  # --------------- #
  # Testing
  # print(paste(yr))
  # yr = 1976
  # --------------- #
  
  # Filter data
  data <- input_data %>% 
    filter(year == yr,
           spp == taxa,
           region == reg
    ) %>% 
    # Average duplicated hauls in the same spot
    group_by(region,year,spp,lat,lon) %>%
    summarise_at(vars(wtcpue),
                 mean,na.rm = T) %>%
    filter(wtcpue > 0)
    
  # Only interpolate cases where there is more than 3 rows
  # Marked by the function 
    if(nrow(data) <= 3){
      fit_tin <- tibble()
    }else{
      
      # Triangular Irregular Surface
      fit_tin <- interp::interp( # using {interp}
        x = data$lon,           # the function actually accepts coordinate vectors
        y = data$lat,
        z = data$wtcpue,
        xo = grid$lon,     # here we already define the target grid
        yo = grid$lat,
        output = "points"
      ) %>% 
        bind_cols() %>% 
        bind_cols(grid) %>%
        mutate(year = yr,
               region = reg,
               spp = taxa) %>% 
        select(index, state, year, region, spp, lon=x, lat=y, value = z)
      
    }
   
    return(fit_tin)
}

# Test me
# Needs variables in Control panel
# Test no data: "Alosa aestivalis", reg = "Northeast US Fall", yr = 1974 
tis(input_data = ocean_data, grid = grid_eez_df, taxa = spp[1], reg = "Northeast US Fall", yr = 1974)

```

### Run function

```{r interpol_run_fun, eval = T, echo = T}


run_tis <- function(input_data, grid, years, taxa, reg){
  
  
  # Run tis for species and surveys
  for(r in 1:2){
    
    partial_df <- bind_rows(
      lapply(years,tis,input_data = ocean_data, grid = grid_eez_df, taxa = taxa, reg = regions[r])
    )
    
    if(r == 1){
      historic_tif <- partial_df
    }else{
      historic_tif <- bind_rows(historic_tif,partial_df)
    }
    
  }
  
  # ----------------------- #
  # Save dataset per species
  # ----------------------- #
  
  # Set file name
  name <- paste0("tif_",str_replace(taxa," ","_"),".csv")
  
  # Set path name
  save_path <- my_path("R","Partial/Interpolation")
  
  # Set complete path
  save_name <- paste0(save_path,name)
  
  # Create folder if it does not exist
  if(file.exists(save_path) == F){
    dir.create(save_path)
  }
  
  #  Save file
  write_csv(historic_tif,save_name)
  
}


```


### Ocean adapt data

- Using only the Northeast US Fall and Spring bottom trawl survey data for now

```{r dat_exploded, eval = T, echo = F}

ocean_data <- readRDS("/Volumes/Enterprise/Data/pinskylab-OceanAdapt-966adf0/data_clean/dat_exploded.rds") #%>% 
  # filter(spp == "Centropristis striata",
       # region %in% c("Northeast US Fall" , "Northeast US Spring")) #No more seasons

subset_data <- ocean_data %>% 
  filter(spp == "Centropristis striata",
       region %in% c("Northeast US Fall" , "Northeast US Spring")
       )

ggplot() +
  geom_point(data = subset(subset_data, wtcpue = 0.0),
             aes(
               x = lon,
               y = lat
             ),
             color = "grey95"
  ) +
  geom_point(data = subset(subset_data, wtcpue > 0),
             aes(
               x = lon,
               y = lat,
               color = log10(wtcpue)
             ),
             size = 1
  ) +
  scale_color_distiller(palette = "Spectral", 
                        guide_legend(title = "WCPUE per Haul (log10)")) + 
  coord_sf(xlim = c(-76, -65),ylim = c(35, 45)) +
  MyFunctions::my_ggtheme_m() +
  facet_wrap(~region)

```

### Control Pannel

Load required data. Note that some of it has been previously created 

```{r contro_pannel, eval = T, echo = T}

# Load grid df
grid_eez_df <- my_path("D","Spatial","grid_eez_df.csv", read = T)

# Run interpolation for all years
years <- seq(1973,2019,1)

# regions
regions <- c("Northeast US Fall" , "Northeast US Spring")


# taxa
# spp <- "Centropristis striata"

spp <- ocean_data %>% 
  filter(region %in% regions,
         spp != "NA") %>% 
  pull(spp) %>% 
  unique()

```

### Run routine

```{r run_routine, eval = T, echo = T}

# Run for a single region
# historic_tif <- bind_rows(
  # lapply(years,tis,input_data = ocean_data, grid = grid, taxa = "Centropristis striata", reg = regions[2])
# )


# # Simple for-loop for running both regions (seasons)
# for(r in 1:2){
#   
#   partial_df <- bind_rows(
#     lapply(years,tis,input_data = ocean_data, grid = grid, taxa = spp, reg = regions[r])
#   )
#   
#   if(r == 1){
#     historic_tif <- partial_df
#   }else{
#     historic_tif <- bind_rows(historic_tif,partial_df)
#   }
#   
# }



# Run for one species
    run_tis(input_data = ocean_data, grid = grid_eez_df, taxa = "Centropristis striata", years = years, reg = regions)

# Run for multiple species
    run_tis(input_data = ocean_data, grid = grid_eez_df, taxa = spp[1], years = years, reg = regions)


# Save data for future plotting
# write_csv(historic_tif,
          # paste0(my_path("R","Partial"),"interpolated_data.csv"))

# Show data in notebook
head(historic_tif,10) %>% 
   kable(
    format = "html",
    caption = "Extrapolated data") %>% 
  kableExtra::kable_minimal() %>% 
  kableExtra::kable_styling() %>%
  kableExtra:: scroll_box(width = "100%", height = "300px")

```


# Results


```{r load_data}

# Load interpolated data
historic_tif <- my_path("R","Partial","interpolated_data.csv",read = T)

# Periods
periods <-tibble(
  period = c(rep("a early",12),
             rep("b mid",12),
             rep("c late",12),
             rep("d now",12)
             ),
  year = c(seq(1972,1984,1),
            seq(1985,1997,1),
            seq(1998,2011,1),
            seq(2012,2019,1)
            )
  )

# State pallet

state_pallet <- c(wes_palette(n = 5, name = "Darjeeling1"),
                               wes_palette(n = 5, name = "Darjeeling2"),
                               wes_palette(n = 3, name = "Royal1")
                  )

```


## Points

```{r area_map_state, eval = T, echo = T, fig.width=10, fig.height=12}

 data_grid <- historic_tif %>% 
  # left_join(periods) %>% 
  # group_by(state,lat,lon,period) %>% 
  group_by(state,lat,lon,region) %>% 
  summarise(mean = mean(value,na.rm= T), .groups = "drop") %>% 
  rename(ID = state)

ggplot(data_grid) +
  geom_tile(
    aes(
      x = lon,
      y = lat,
      fill = mean,
      col = mean
    )
  ) +
  facet_wrap(~ ID  +  region,
             ncol = 4) +
  scale_fill_viridis("Mean Proportion", alpha = 0.8) +
  scale_color_viridis("Mean Proportion", alpha = 0.8)


```

## Map

```{r area_map, eval = T, echo = T, fig.width = 10}

total_fited <- historic_tif %>% 
  group_by(year,region) %>% 
  summarise(total_value = sum(value,na.rm=T))

state_fit <- historic_tif %>% 
  group_by(state,year,region) %>% 
  summarise(state_value = sum(value,na.rm= T), .groups = "drop") %>% 
  left_join(total_fited,
            by = c("year","region")) %>%
  mutate(percentage = state_value/total_value*100) %>% 
  left_join(periods) %>% 
  group_by(ID = state,period,region) %>% 
  summarise(mean_per = round(mean(percentage)))
  
# check percentages
# state_fit %>% 
#   group_by(period) %>% 
#   summarise(sum(mean_per))


land_sf %>% 
  left_join(state_fit,
            by = "ID") %>% 
  ggplot() +
  geom_sf(aes(fill = mean_per)) +
  viridis::scale_fill_viridis("Mean Proportion", alpha = 0.8) +
  facet_wrap(~region + period, nrow = 2) +
  my_ggtheme_m()

```

## Area plot

This graph shows the proportion of each State over time

```{r area_plot, eval = T, echo = T, fig.height = 10, fig.width = 10}

total_fited <- historic_tif %>% 
  group_by(year,region) %>% 
  summarise(total_value = sum(value,na.rm=T))

# group by state
state_fit <- historic_tif %>% 
  group_by(state,year,region) %>% 
  summarise(state_value = sum(value,na.rm= T), .groups = "drop") %>% 
  left_join(total_fited,
            by = c("year","region")) %>%
  mutate(percentage = state_value/total_value*100) %>% 
  group_by(state,region)

p <- ggplot(state_fit) +
  geom_area(
    aes(
      x = year,
      y = round(percentage),
      fill = state
    )
  ) +
  ylab("Percentage (%)") +
  # viridis::scale_fill_viridis(discrete = T, alpha = 0.8) +
  scale_fill_manual(values = state_pallet) +
  MyFunctions::my_ggtheme_p() +
  facet_wrap(~region, ncol = 1)

ggplotly(p,
         dynamicTicks = TRUE) %>% 
  layout(hovermode = "x") %>% 
  # add_trace() %>% 
  rangeslider()

```
## Area plot (running)

This graph shows the proportion of each State smoothed over a 10 years running mean. It helps seeing the trends better (I Think...)

```{r area_lm_plot, eval = T, echo = T, fig.height = 10, fig.width = 10}

# group by state
state_fit <- historic_tif %>% 
  group_by(state,year,region) %>% 
  summarise(state_value = sum(value,na.rm= T), .groups = "drop") %>% 
  left_join(total_fited,
            by = c("year","region")) %>%
  mutate(percentage = state_value/total_value*100) %>% 
  group_by(state,region) %>% 
  mutate(RMean = zoo::rollmean(x = percentage, 
                            10,
                            fill = NA,
                            na.rm=T)
    )

# Plot me
p <- ggplot(state_fit) +
  geom_area(
    aes(
      x = year,
      y = round(RMean),
      fill = state
    )
  ) +
  ylab("10 yrs running average (%)") +
  # viridis::scale_fill_viridis(discrete = T, alpha = 0.8) +
  scale_fill_manual(values = state_pallet) +
  MyFunctions::my_ggtheme_p() +
  facet_wrap(~region, ncol = 1)

suppressWarnings(
ggplotly(p,
         dynamicTicks = TRUE) %>% 
  layout(hovermode = "x") %>% 
  # add_trace() %>% 
  rangeslider()
)

```
