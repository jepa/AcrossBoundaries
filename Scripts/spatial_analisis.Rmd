---
title: "Spatial Analysis"
author: "Juliano Palacios Abrantes"
output:
  # html_document
  html_notebook:
    fig_width: 6
    fig_height: 4
    code_folding: hide
    toc: yes
    toc_depth: 3
    toc_float:
      collapsed: false
    theme: darkly
---

```{r setup, include=FALSE}
library(MyFunctions)
MyFunctions::my_lib(c("ggmap","sf","st","tidyverse","tools","readr","data.table","maps","viridis","wesanderson","knitr","kableExtra","plotly","ggrepel","ggsflabel","janitor","interp","rnaturalearth","readxl"))

# Fix new updats of sf package
sf::sf_use_s2(use_s2 = FALSE)


# Create specific state pallet from our friend Wes Andersson
state_pallet <- c(wes_palette(n = 5, name = "Darjeeling1"),
                               wes_palette(n = 5, name = "Darjeeling2"),
                               wes_palette(n = 3, name = "Royal1")
                  )

```

# Methods

## Spatial data preparation

### Load data

#### Maps data

We use three different shapefiles for the continental U.S. land mass, the State waters of maine, new hampshire, massachusets, connecticut, rhode island, new york, new jersey, delaware, maryland, virginia, north carolina and the North East EEZ. Moreover, we use the NOAA dataset of landings per port.

##### 1.- Land shapefile

Covers the US land territory for visualization. Data provided from the `map` package.


```{r land_sf, eval = T, echo = T, results = 'hide'}

States <- c("maine", "new hampshire", "massachusetts", "connecticut", "rhode island", "new york", "new jersey", "delaware", "maryland", "virginia", "north carolina") 

# -------------- #
# US State Map (land)
# -------------- #

land_sf <- st_as_sf(map("state", plot = FALSE, fill = TRUE)) %>% 
  filter(ID %in% States) %>% 
  mutate(abrev = c("CT","DE","ME","MD","MA","NH","NJ","NY","NC","RI","VA"),
         state = str_to_sentence(ID)
         )

# Visual exploration (o.k! )
ggplot(land_sf) +
  geom_sf(aes(fill = state)) +
  scale_fill_manual(values = state_pallet) +
  theme_dark()
          

```

#####  2.- EEZ shapefile

Used the *Sea Around Us* shapefle updated to June 2016.

```{r eez_sf, eval = T, echo = T}

# US EEZ map
path_world <- my_path("G", extra_path = "Spatial/SAU/SAU_Shapefile", name = "SAUEEZ_July2015.shp")

# Load it!
eez_sf <- st_read(path_world) %>%
  rename(eez_name = Name) %>%
  st_transform(crs = 4326) %>% # 4326
  filter(eez_name == "USA (East Coast)") %>%
  st_simplify(preserveTopology = TRUE, dTolerance = 0.1) #0.1 for paper

# Visual exploration (o.k! )
ggplot(eez_sf) +
  geom_sf() +
  theme_dark()

```

#####  3.-  State waters

Covers the state waters of the NE US states. Data from [data.gov](https://catalog.data.gov/dataset/federal-and-state-waters).  

*License: No license information was provided. If this work was prepared by an officer or employee of the United States government as part of that person's official duties it is considered a U.S. Government Work.*

```{r state_sf, eval = T, echo = T}

# us_state_file <- my_path("G", extra_path = "Spatial/USFedAndStateW/FederalAndStateWaters.gdb")

state_sf <-  st_read("~/OneDrive - UW-Madison/Spatial_Data/USFedAndStateW/FederalAndStateWaters.gdb") %>%
  janitor::clean_names() %>% 
  mutate(jurisdicti = str_to_lower(jurisdicti)) %>% 
  filter(jurisdicti %in% States) %>% 
  mutate(state = str_to_sentence(jurisdicti)) %>% 
  st_transform(crs = 4326) %>%   # for matching projections
  st_simplify(preserveTopology = TRUE, dTolerance = 10000) #0.1 for paper


# Visual exploration (o.k! )
ggplot(state_sf) +
  geom_sf(aes(fill = state)) +
  scale_fill_manual(values = state_pallet) +
  theme_dark()

```

##### 4.- Fishing ports

We used [Global Fishing Watch](https://globalfishingwatch.org/datasets-and-code-anchorages/)'s database on 
Anchorages, Ports and Voyages.

*The Global Fishing Watch anchorages dataset is a global database of anchorage locations where vessels congregate. The dataset contains over 160,000 individual anchorage locations, which are further grouped into nearly 32,000 ports when applicable.*


```{r ports_sf, eval = T, echo = T}

# Get Global Fishig Watch data
gfw_data <- my_path("D","Spatial",name = "gfw_portdata.csv", read = T) %>% 
  filter(iso3 == "USA") 

# Visualize data (o.k!)
# ggplot(gfw_data) +
#   geom_point(
#     aes(
#     x = lon,
#     y = lat
#   )
#   )

# Convert data to sf for mergig
gfw_sf <- st_as_sf(gfw_data,
             coords = c("lon", "lat"),
             crs = 4326)

# Merge data with state waters to,locate ports 
port_sf <- st_join(gfw_sf,state_sf) %>% 
  filter(!is.na(jurisdicti)) # remove points outside stat waters

ggplot(port_sf)  +
  geom_sf(aes(color = distance_from_shore_m)) +
  theme_dark()

```
So...Looks like some ports are "far from shore" which I don't really know what it means. For now, I am only selecting those ports that ar 0 meter from shore. 


```{r ports_inshore, eval = T, echo = F}

# Get numner of ports per state
ports_n_data <- port_sf %>% 
  as.data.frame() %>% 
    filter(distance_from_shore_m == 0) %>% 
    group_by(state) %>% 
    summarise(n_ports = n()) 

# plot it
gridExtra::grid.arrange(
  port_sf %>% 
    filter(distance_from_shore_m == 0) %>% 
    ggplot()  +
    geom_sf(aes(color = jurisdicti)) +
    scale_color_manual(values = state_pallet) +
    theme_dark() +
    theme(legend.position = ""),
  tableGrob(ports_n_data),
  ncol = 2
)


```


There are still too many ports in each state (?). Specially New Jersey! One approach is to use NOAA's landing-per-port data to filter out... 

###### 4.1 NOAA's data

This dataset includes all landings from 2015-July 2021. It includes the species landed, the port, and the Hull ID and vessel name for black sea bass and summer flounder.

*License, from Sarah Smith: This is confidential data, so please do not share this file with others. You may need to contact NOAA directly just to request permission. My contact has been Alison Ferguson (Alison.Ferguson@noaa.gov) in their data department.*

```{r}

### SRAH LANDING DATA
read_excel_allsheets <- function(filename, tibble = TRUE) {
    # I prefer straight data.frames
    # but if you like tidyverse tibbles (the default with read_excel)
    # then just pass tibble = TRUE
    sheets <- readxl::excel_sheets(filename)[2:8]
    x <- lapply(sheets, function(X) readxl::read_excel(filename, sheet = X))
    if(!tibble) x <- lapply(x, as.data.frame)
    names(x) <- sheets
    x
}
# Get data path
ports_path <- my_path("D","NOAA", name = "SSmith_2015-2021 Landings_JUN 2021.xlsx")

# 
ports_data <- bind_rows(read_excel_allsheets(ports_path)) %>%
  clean_names() %>%
  mutate_if(is.character,
              ~ str_to_lower(.)) %>% 
  mutate(landing_port = str_remove(landing_port,"[:blank:]\\(state\\)"))

noaa_ports <- unique(ports_data$landing_port)

noaa_port <- port_sf %>% 
  filter(distance_from_shore_m == 0) %>% 
  mutate(label = str_to_lower(label)) %>% 
  filter(label %in% noaa_ports)

# Get number of ports per state
noaa_ports_n_data <- noaa_port %>% 
  as.data.frame() %>% 
    group_by(state) %>% 
    summarise(noaa_ports = n()) 

# Get number of ports in the NOAA database

n_ports_data <- ports_data %>% 
  group_by(landing_state) %>% 
  summarise(noaa_ports = length(unique(landing_port))) %>% 
  mutate(abrev = str_to_upper(landing_state)) %>% 
  left_join(land_sf) %>% 
  select(state,noaa_ports) %>% 
  filter(!is.na(state)) %>% 
  left_join(noaa_ports_n_data)

# plot it
gridExtra::grid.arrange(
  port_sf %>% 
    mutate(label = str_to_lower(label)) %>% 
    filter(distance_from_shore_m == 0,
           label %in% noaa_ports
           ) %>% 
    ggplot()  +
    geom_sf(aes(color = jurisdicti)) +
    scale_color_manual(values = state_pallet) +
    theme_dark(),
    # theme(legend.position = ""),
  tableGrob(n_ports_data),
  ncol = 2
)
  
```


This approach removes a lot of ports to the point that Delaware is completely port-less

###### 4.2 World Port Index 

In this approach we only use the ports categorized within the [WPI](https://msi.nga.mil/NGAPortal/MSI.portal?_nfpb=true&_pageLabel=msi_portal_page_62&pubCode=0015) and with `distance_from_shore_m == 0`  and `at_dock == TRUE`.

- `at_dock` == Anchorages within a 450 meter buffer around a combined land shape file are considered at dock. 

```{r wpi_approach, eval = T, echo = F}

gridExtra::grid.arrange(
  port_sf %>% 
    filter(distance_from_shore_m == 0,
           label_source %in% c("WPI_ports"),
           at_dock == TRUE) %>% 
    ggplot()  +
    geom_sf(aes(color = jurisdicti)) +
    scale_color_manual(values = state_pallet) +
    theme_dark(),
  port_sf %>% 
    as.data.frame() %>% 
    filter(distance_from_shore_m == 0,
           label_source %in% c("WPI_ports"),
           at_dock == TRUE) %>% 
    group_by(state) %>% 
    summarise(n_ports = n()) %>% 
    tableGrob(),
  ncol = 2
)


```

This approach might be better suited. It also has teh advantage that we are using the WPI.

This is how all the shapefiles look like together


```{r all_sf, eval = T, echo = T}

port_sf <- port_sf %>% 
    filter(distance_from_shore_m == 0,
           label_source %in% c("WPI_ports"),
           at_dock == TRUE)

# Visual exploration of all together (o.k! )
ggplot() +
  geom_sf(data = eez_sf, aes()) +
  geom_sf(data = land_sf, aes(fill = state), alpha = 0.3) +
  geom_sf(data = state_sf, aes(color = state), fill = NA) +
  geom_sf(data = port_sf, aes(color = state)) +
  scale_color_manual(values = state_pallet) +
  scale_fill_manual(values = state_pallet) +
  theme_dark() +
  coord_sf(ylim = c(33,48))

```


### Create base shapefile for computation

As a first step we need to divide the NE US EEZ among the different states. For that, we expanded a buffer-polygon to the 200 nautical miles to then estimate the percentage that each expanded polygon occupied. For the initial buffer point we used two approaches; state waters and US ports. Note that in all cases these areas overlapped and percentages accounted for it. We did this by following these steps:

- 1. Expand state waters / US ports using a buffer

- 2. Grid that buffer on a 0.3 resolution

- 3. Crop the buffer to the EEZ

#### 1. Expand Spatial regions (a.k.a  buffers)

##### 1.1 State Waters

We set a buffer of *410000* m (410 km, ~ 221 nm) that overshoots the EEZ a bit, but is eventually cropped

```{r sw_buffer, eval = T, echo = T}

# Buffer state waters
state_bf = st_buffer(state_sf, 4) %>% 
  st_transform(4326) %>% # to match shape
  st_set_crs(4326)

# ------------------------------ #
# Testing and visualizing the buffer 
# ------------------------------ #

state_bf_plot <- ggplot() +
  geom_sf(data = state_sf, aes(color = state), fill = NA) +
  geom_sf(data = eez_sf, aes(), fill = NA) +
  geom_sf(data = state_bf, aes(color = state), fill = NA) +
  scale_color_manual(values = state_pallet)+
  theme_dark()
#   

# ggsave("../Results/Partial/state_waters_buffer.png",state_bf_plot)

# ------------------------------ #

state_bf_plot

```

##### 1.1 US. Ports

We set a buffer of *5* deg (510 km, ~ 221 nm) that overshoots the EEZ a bit, but is eventually cropped

```{r fp_buffer, eval = T, echo = T}

# Buffer state waters
port_bf = st_buffer(port_sf, 5) %>% # port
  st_transform(4326) %>% # to match shape
  st_set_crs(4326)

# ------------------------------ #
# Testing and visualizing the buffer 
# ------------------------------ #

ggplot() +
  geom_sf(data = eez_sf, aes(),fill = NA) +
  geom_sf(data = port_bf, aes(color = state), fill = NA) +
  scale_color_manual(values = state_pallet)+
  theme_dark()

```


#### 2. Expand grid within buffer

Here we expand a grid within the buffer so we can estimate the proportion of each state.

*Note:* Dark grey shaded area is the grid and is the same for both approaches

```{r grid_indexing, eval = T, echo = T, message = F, warning = F}

# Create grid of the region
bbox <- c(st_bbox(state_bf))

# Expand the grid
ne_grid <- expand.grid(
    lon = seq(from = bbox["xmin"], to = bbox["xmax"], by = 0.3),
    lat = seq(from = bbox["ymin"], to = bbox["ymax"], by = 0.3)
) %>% 
  rowid_to_column("index")

# ----------- #
# [TEST] Plot all layers
# ----------- #

# Looks good
state_sf %>%
  st_transform(4326) %>% # to match shape
  st_set_crs(4326) %>%
  # st_simplify(preserveTopology = TRUE, dTolerance = 10000) %>%
  ggplot() +
  geom_sf(aes(color = state))+
  # geom_sf(data = eez_sf, aes(),fill =NA) +
  # ggplot()+
  geom_tile(data = ne_grid,
            aes(
              x = lon,
              y = lat
            ),
            alpha = 0.2
  ) +
  scale_color_manual(values = state_pallet) +
  theme_bw() +
  theme_dark()


```

##### 2.1 Merge grid and buffers

Once we have a gridded area, we converted the grid to a `sf` so we can merge it with the buffered states and ports and finally filter out everything outside the states polygon

###### 2.1.1 State Waters

```{r grid_sw_buf_merge, eval = T, echo = T, message = F, warning = F, fig.width = 10}

# ---------------- #
# Convert grid to sf
# ---------------- #
grid_sw_sf <- st_as_sf(ne_grid,
             coords = c("lon", "lat"),
             crs = 4326) %>% 
  st_join(state_bf) %>% 
  filter(!is.na(state))

# Create data frame for future computations
# Note, will be used in next chunk
grid_sw_bf_dt <- as.data.frame(grid_sw_sf) %>%
    select(index,state)
    # group_by(state) %>% 
    # summarise(length(index))


# ---------------- #
# [TEST] 
# Visualization of grid
# ---------------- #

gridExtra::grid.arrange(
  # Overall (overlapping) position
  ggplot(grid_sw_sf) +
    geom_sf(data = state_sf, aes(), fill = NA) +
    geom_sf(aes(color = state), alpha = 0.3) +
    geom_sf(data = eez_sf, aes(),fill =NA) + 
    scale_color_manual(values = state_pallet) +
    theme_dark() +
    theme(legend.position = ""),
  # Showing each state separatley
  ggplot() +
    geom_sf(data = grid_sw_sf, aes(color = state),size = 0.1, alpha = 0.5) +
    facet_wrap(~state) +
    theme_dark() +
    theme(legend.position = "top") +
    scale_color_manual(values = state_pallet),
  nrow = 1) 

```

###### 2.1.1 Fishing Ports

```{r grid_fp_buf_merge, eval = T, echo = T, message = F, warning = F, fig.width = 10}

# ---------------- #
# Convert grid to sf
# ---------------- #
grid_fp_sf <- st_as_sf(ne_grid,
             coords = c("lon", "lat"),
             crs = 4326) %>% 
  st_join(port_bf) %>% # join to port sf
  filter(!is.na(state)) %>% 
  distinct(index,state, .keep_all = TRUE) #removes like 400K overlapping rows

# Create data frame for future computations
# Note, will be used in next chunk
grid_fp_bf_dt <- as.data.frame(grid_fp_sf) %>%
    select(index,state)

# ---------------- #
# [TEST] 
# Visualization of grid
# ---------------- #

gridExtra::grid.arrange(
  # Overall (overlapping) position
  ggplot(grid_fp_sf) +
    geom_sf(data = port_sf, aes(), fill = NA) +
    geom_sf(aes(color = state), alpha = 0.3) +
    geom_sf(data = eez_sf, aes(),fill =NA) + 
    scale_color_manual(values = state_pallet) +
    theme_dark() +
    theme(legend.position = ""),
  # Showing each state separately
  ggplot() +
    geom_sf(data = grid_fp_sf, aes(color = state),size = 0.1, alpha = 0.5) +
    facet_wrap(~state) +
    theme_dark() +
    theme(legend.position = "top") +
    scale_color_manual(values = state_pallet),
  nrow = 1)

```

#### 3. Crop buffers to EEZ

Finally, we crop the grided buffers to within the EEZ to capture the actual water space.

*Note:* This step takes quite a while because of the size of the EEZ shapefile. No, you cannot use `st_simplify()` here

#### 3.1 State Waters

```{r buff_sw_to_eez, eval =T, echo = T, message = F, warning = F}

# I don't know how to undo st_simplify so need to re-load the shapefile

eez_sf <- st_read(my_path("G", extra_path = "Spatial/SAU/SAU_Shapefile", name = "SAUEEZ_July2015.shp")) %>% 
  rename(eez_name = Name) %>% 
  st_transform(crs = 4326) %>% # 4326
  filter(eez_name == "USA (East Coast)") 

# Get the overlapping segments 
# NOTE: Takes some gooooood time (~20 min)
Sys.time()
grid_eez_sf_sw <- st_intersection(grid_sw_sf,eez_sf)
Sys.time()
# write_sf(grid_eez_sf, paste0(my_path("D", "Spatial"),"grid_eez_sf.shp"))

# Get final df with index
grid_eez_sw_df <- as.data.frame(grid_eez_sf_sw) %>%
  select(state,index) %>%
  left_join(ne_grid,
            by = "index")

# write_csv(grid_eez_df, paste0(my_path("R", "Partial"),"grid_eez_df.csv"))

# Plot to make sure makes sense

eez_sf <- eez_sf %>% 
  st_simplify(preserveTopology = TRUE, dTolerance = 0.1) #0.1 for paper

grid_eez_sf_sw %>%
  ggplot() +
  geom_sf(aes(color = state), alpha = 0.3) +
  scale_color_manual(values = state_pallet) +
  geom_sf(data = eez_sf,aes(), fill = NA) +
  theme_dark()

```


#### 3.2 Fishing Ports

```{r buff_fp_to_eez, eval =T, echo = T, message = F, warning = F}

# Get the overlapping segments 
# NOTE: Takes some gooooood time (~20 min)
Sys.time()
grid_eez_fp_sw <- st_intersection(grid_fp_sf,eez_sf)
Sys.time()
# write_sf(grid_eez_sf, paste0(my_path("D", "Spatial"),"grid_eez_sf.shp"))

# Get final df with index
grid_eez_fp_df <- as.data.frame(grid_eez_fp_sw) %>%
  select(state,index) %>%
  left_join(ne_grid,
            by = "index")

# write_csv(grid_eez_df, paste0(my_path("R", "Partial"),"grid_eez_df.csv"))

# Plot to make sure makes sense
grid_eez_fp_sw %>%
  ggplot() +
  geom_sf(aes(color = state), alpha = 0.3) +
  scale_color_manual(values = state_pallet) +
  geom_sf(data = eez_sf,aes(), fill = NA) +
  theme_dark()

```

#### 3.3 Differences at cropede level

By looking at the plots we do not see that the number of grid cells that each state has is slightly different depending on the approach. This comes to light when we count the number of gridcells that each state gets in each approach. We see that the state waters one is substantially higher.

We can visualize the difference of the cropped area for each state next. Again, the fishing port approach results in less area for all states, but such area is not proportional among states. For example, Delaware looses roughly 35% of fishing grounds with this approach

```{r state_bf_diff_tbl, eval = T, echo = T}

grid_eez_sw_df %>% 
  mutate(approach = "state_waters") %>% 
  bind_rows(grid_eez_fp_df) %>%
  mutate(approach = ifelse(is.na(approach),"fishing_port",approach)) %>% 
  group_by(state,approach) %>% 
  summarise(n_grid = n()) %>% 
  spread(approach,n_grid) %>% 
  mutate(difference =state_waters-fishing_port,
         percentage_sw = round((difference/state_waters)*100)
         )

```

And here is the map visualization of the cropped difference

```{r state_bf_diff_map, eval = T, echo = T}

grid_eez_sw_df %>% 
  mutate(approach = "state_waters") %>% 
  bind_rows(grid_eez_fp_df) %>%
  mutate(approach = ifelse(is.na(approach),"fishing_port",approach)) %>% 
  ggplot() +
  geom_tile(
    aes(
      x = lon,
      y = lat,
      color = approach,
      fill = approach
    )
  ) +
  facet_wrap(~state) +
  scale_color_brewer(palette = "Set2") +
  scale_fill_brewer(palette = "Set2") +
  theme_dark()

```

##### 3.1 Paper figure; buffer plot

```{r cropped_plot_paper, eval = F, echo = T}


plot_data <-grid_eez_sf %>% 
    mutate(state = str_to_sentence(state)) %>% 
    left_join(state_lat)

p <- gridExtra::grid.arrange(
  # Overall (overlapping) position
  ggplot(plot_data) +
    geom_sf(data = eez_sf, aes(), fill = "white") + 
    geom_sf(aes(color = order, fill = order), alpha = 0.3) +
    geom_sf(data = land_sf, aes()) +
    geom_sf_label_repel(data = land_sf, aes(label= abrev), 
                      size = 2,
                      box.padding = 0.10,
                      hjust = 1) +
    scale_color_manual(values = state_pallet) +
    scale_fill_manual(values = state_pallet) +
    my_ggtheme_p(leg_pos = "",
                 ax_tx_s = 12) +
    coord_sf(ylim = c(30,48)) +
    scale_y_continuous(breaks = c(30,35,40,45))+
    labs(x = "", y = ""),
  # Showing each state separately
  
    ggplot(plot_data) +
    geom_sf(data = land_sf, aes(), fill = "grey80") +
    geom_sf( aes(color = order),size = 0.1, alpha = 0.8) +
    facet_wrap(~ state) +
    theme(legend.position = "top") +
    scale_color_manual(values = state_pallet,
                       labels = plot_data %>% arrange(order) %>%  pull(state) %>% unique()) +
    my_ggtheme_p(leg_pos = "",
                 ax_tx_s = 6,
                 axx_tx_ang = 45,
                 hjust = 1
                 ),
  nrow = 1,
  bottom = "Longitude",
  left = "Latitude")


  ggsave(filename = "buffer_figure.jpg",
         plot = p,
         path = my_path("R","Figures"),
         width = 10,
         height = 5
         )

```

![Buffer figure for paper](/Volumes/Enterprise/Data/AcrossBoundaries/Results/Figures/buffer_figure.jpg)




```{r remove_pen, eval = F, echo = F}

####____________________________________________### 
# Solving for Issue #8 Pennsylvania has NO coast
####____________________________________________### 

# Remove Pennsylvania from sf
grid_eez_sf <-  st_read("/Volumes/Enterprise/Data/AcrossBoundaries/Data/Spatial/grid_sf/grid_eez_sf.shp") %>%
  filter(state != "pennsylvania")

# Make sure no Penn.
unique(grid_eez_sf$state)

# over write sf
write_sf(grid_eez_sf, paste0(my_path("D", "Spatial"),"grid_eez_sf.shp"))

#Make sure of things

# grid_eez_sf <-  st_read("/Volumes/Enterprise/Data/AcrossBoundaries/Data/Spatial/grid_sf/grid_eez_sf.shp")

# unique(grid_eez_sf$state)

# Now save it as a DF too

# grid_eez_df <- as.data.frame(grid_eez_sf) %>%
  # select(state,index) %>%
  # left_join(ne_grid,
            # by = "index")

# write_csv(grid_eez_df, paste0(my_path("R", "Partial"),"grid_eez_df.csv"))
```


### Interpolation rutine

In this step we [interpolate](https://swilke-geoscience.net/post/spatial_interpolation/) the survey data within the previously created grid following a Triangular Irregular Surface method.

- We removed cases where `wtcpue < 0`

#### Functions needed

We need to create a couple of functions to run the whole process

##### Interpolation main fx (tis).

This is the main function used to interpolate the data per year. It follows a Triangular Irregular Surface method using the `interp::interp()` function. If you want to see the function clic on `code`

```{r interpol_function, eval = T, echo = T}

tis <- function(input_data, grid, yr, taxa, reg){
  
  # --------------- #
  # Testing
  # print(paste(yr))
  # yr = 1976
  # --------------- #
  
  # Filter data
  data <- input_data %>% 
    filter(year == yr,
           spp == taxa,
           region == reg
    ) %>% 
    # Average duplicated hauls in the same spot
    group_by(region,year,spp,lat,lon) %>%
    summarise_at(vars(wtcpue),
                 mean,na.rm = T)
    
  # Only interpolate cases where there is more than 3 rows
  # Marked by the function 
    if(nrow(data) <= 3){
      fit_tin <- tibble()
    }else{
      
      # Triangular Irregular Surface
      fit_tin <- interp::interp( # using {interp}
        x = data$lon,           # the function actually accepts coordinate vectors
        y = data$lat,
        z = data$wtcpue,
        xo = grid$lon,     # here we already define the target grid
        yo = grid$lat,
        output = "points"
      ) %>% 
        bind_cols() %>% 
        bind_cols(grid) %>%
        mutate(year = yr,
               region = reg,
               spp = taxa) %>% 
        select(index, state, year, region, spp, lon=x, lat=y, value = z)
      
    }
   
    return(fit_tin)
}

# Test me
# Needs variables in Control panel
# Test no data: "Alosa aestivalis", reg = "Northeast US Fall", yr = 1974 
# tis(input_data = ocean_data, grid = grid_eez_df, taxa = "Illex illecebrosus", reg = "Northeast US Fall", yr = 1973)



# lapply(years,tis,input_data = ocean_data, grid = grid_eez_df, taxa = "Illex illecebrosus", reg = regions[2])

```

##### Run function

This is a sub-function that runs the `tis()` function by taxa and region. It saves the output as a .csv file for each species. 

```{r interpol_run_fun, eval = T, echo = T}


run_tis <- function(input_data, grid, years, taxa, reg){
  
  
  # Run tis for species and surveys
  for(r in 1:2){
    
    partial_df <- bind_rows(
      lapply(years,tis,input_data = ocean_data, grid = grid_eez_df, taxa = taxa, reg = regions[r])
    )
    
    if(r == 1){
      historic_tif <- partial_df
    }else{
      historic_tif <- bind_rows(historic_tif,partial_df)
    }
    
  }
  
  # ----------------------- #
  # Save dataset per species
  # ----------------------- #
  
  # Set file name
  name <- paste0("tif_",str_replace(taxa," ","_"),".csv")
  
  # Set path name
  save_path <- my_path("R","Partial/Interpolation")
  
  # Set complete path
  save_name <- paste0(save_path,name)
  
  # Create folder if it does not exist
  if(file.exists(save_path) == F){
    dir.create(save_path)
  }
  
  #  Save file
  write_csv(historic_tif,save_name)
  
  return_msg <- paste("Interpolation done for", taxa)
  
  return(return_msg)
  
  
}

# Test me
    # run_tis(input_data = ocean_data, grid = grid_eez_df, taxa = "Centropristis striata", years = years, reg = regions)

```


#### Survey data

The interpolation was done with NOAA Northeast Fisheries Science Center Spring and Fall Bottom Trawl Surveys [data](https://www.fisheries.noaa.gov/region/new-england-mid-atlantic#science) provided by [Ocean adapt](https://oceanadapt.rutgers.edu/). Data was accessed trough the [Github](https://github.com/pinskylab/OceanAdapt).

*In primary publications using data from the database, please cite Pinsky et al. 2013. Marine taxa track local climate velocities. Science 341: 1239-1242 doi: 10.1126/science.1239352, as well as the original data sources.*

- Using only the Northeast US Fall and Spring bottom trawl survey data for now

##### Splitting up data

- No part on spatial analysis. Can be ignored. 

This is just a sub-step to split up the data into single species files. This makes the app faster as it only needs to load species specific data, rather than all the data at de beginning. 

```{r dat_exploded, eval = F, echo = F, fig.width = 9}

ocean_data <- readRDS("/Volumes/Enterprise/Data/pinskylab-OceanAdapt-966adf0/data_clean/dat_exploded.rds") #%>% 
  # filter(spp == "Centropristis striata",
       # region %in% c("Northeast US Fall" , "Northeast US Spring")) #No more seasons


spp_data <- function(spp){
  
  name_save <- paste0(my_path("D","Spp/Observation"),"obs_",str_replace(spp[1], " ", "_"),".csv")

ocean_data %>% 
  filter(spp == spp,
       region %in% c("Northeast US Fall" , "Northeast US Spring")
       ) %>% 
  write_csv(., name_save)
  
}

spp_list <- ocean_data %>% 
  filter(region %in% regions,
         spp != "NA") %>% 
  pull(spp) %>% 
  unique()
  

lapply(spp_list, spp_data)


subset_data <- ocean_data %>% 
  filter(spp == "Centropristis striata",
       region %in% c("Northeast US Fall" , "Northeast US Spring")
       )

ggplot() +
  geom_point(data = subset(subset_data, wtcpue = 0.0),
             aes(
               x = lon,
               y = lat
             ),
             color = "grey95"
  ) +
  geom_point(data = subset(subset_data, wtcpue > 0),
             aes(
               x = lon,
               y = lat,
               color = log10(wtcpue)
             ),
             size = 1
  ) +
  scale_color_distiller(palette = "Spectral", 
                        guide_legend(title = "WCPUE per Haul (log10)")) + 
  coord_sf(xlim = c(-76, -65),ylim = c(35, 45)) +
  MyFunctions::my_ggtheme_m() +
  facet_wrap(~region)

```

#### Control Pannel

This is where we load the required data and prepare to run the interpolation function. Note that some of the data here has been previously created 

```{r contro_pannel, eval = T, echo = T}

# Load grid df
grid_eez_df <- my_path("D","Spatial","grid_eez_df.csv", read = T)

# Run interpolation for all years
years <- seq(1973,2019,1)

# regions
regions <- c("Northeast US Fall" , "Northeast US Spring")

# species list
spp <- ocean_data %>% 
  filter(region %in% regions,
         spp != "NA") %>% 
  pull(spp) %>% 
  unique()


# Double check runs

spp_runs <- tibble(taxa = (list.files(my_path("R","Partial/Interpolation")))) %>%
  mutate(
    taxa = str_remove(taxa, "tif_"),
    taxa = str_remove(taxa, ".csv"),
    taxa = str_replace(taxa, "_", " ")
  ) 

# Missing runs
spp <- tibble(taxa=spp) %>% 
  anti_join(spp_runs) %>% 
  pull(taxa)


```

#### Run routine

Here we just run the routine for each of the species present in the Northeast US Fall and Spring surveys between 1973 and 2019. 

- Note there are 43 identified taxa
- Some taxa do not have presence data in some years

```{r run_routine, eval = T, echo = T}

# single species run
# run_tis(input_data = ocean_data,
#         grid = grid_eez_df,
#         years = years,
#         reg = regions,
#         taxa = "Illex illecebrosus"
# )


# Run them all in parallel
lapply(spp,
                   run_tis, 
                   input_data = ocean_data,
                   grid = grid_eez_df,
                   years = years,
                   reg = regions
)


```

# Results

Results are now for eight species managed under Mid-Atlantic Council Management Plans according to [NOAA](https://www.fisheries.noaa.gov/new-england-mid-atlantic/commercial-fishing/new-england-mid-atlantic-fishery-management-plans).


*Scomber scombrus*, *Peprilus triacanthus* (butterfish), *Illex illecebrosus* (shortfin squid), *Paralichthys dentatus* (summer flounder), *Stenotomus chrysops* (Scoop), *Centropristis striata* (black sea bass), *Pomatomus saltatrix* (Bluefish), *Lopholatilus chamaeleonticeps* (Golden tilefish), *Caulolatilus microps* (blueline tilefish) and *Clupea harengus*


```{r load_data, eval = T, echo = T}

# Species data

# Load interpolated data
# "Centropristis striata"
# 
# historic_tif <- my_path("R","Partial/Interpolation","tif_Centropristis_striata.csv", read = T) %>% 
#   mutate(state = str_to_sentence(state))


# Multiple species

# Managed species by Mid-Atlantic Council Management Plans, and State waters
# https://www.fisheries.noaa.gov/new-england-mid-atlantic/commercial-fishing/new-england-mid-atlantic-fishery-management-plans

Species <- c(
  # "Scomber scombrus",
  # "Doryteuthis (Amerigo) pealeii", #longfin squid WE DONT HAVE IT
  # "Peprilus triacanthus", # butterfish
  # "Illex illecebrosus", #shortfin squid
  "Paralichthys dentatus", #summer flounder
  "Stenotomus chrysops", #Scup"
  "Centropristis striata"#, # black sea bass
  # "Pomatomus saltatrix", # Bluefish
  # "Lopholatilus chamaeleonticeps", #golden tilefish
  # "Caulolatilus microps", #blueline tilefish
  # "Clupea harengus" # Atlantic herring (Jointly in State and Federal Waters)
  )


spp_paths <- list.files(my_path("R",extra_path = "Partial/Interpolation"))

# Some gibiris for names
taxon_list <- gsub("_"," ",spp_paths)
taxon_list <- gsub("tif ","",taxon_list)
taxon_list <- gsub(".csv","",taxon_list)

taxon_list <- taxon_list[taxon_list %in% Species]

# Now set a list of files to read
taxon_read <- paste0("tif_",taxon_list,".csv")
taxon_read <- gsub(" ","_",taxon_read)

taxon_read <- spp_paths[spp_paths %in% taxon_read]

taxon_read <- paste0(my_path("R",extra_path = "Partial/Interpolation"),taxon_read)


# Load all sp in one table
historic_spp <- bind_rows(lapply(taxon_read, fread)) %>% 
  mutate(state = str_to_sentence(state))


unique(historic_spp$spp)

# Spatial data
States <- c("maine", "new hampshire", "massachusetts", "connecticut", "rhode island", "new york", "new jersey", "delaware", "maryland", "virginia", "north carolina") 

# US State Map (land)
land_sf <- st_as_sf(map("state", plot = FALSE, fill = TRUE)) %>% 
  filter(ID %in% States) %>% 
  mutate(abrev = c("CT","DE","ME","MD","MA","NH","NJ","NY","NC","RI","VA"),
         state = str_to_sentence(ID)
         )

# Periods
periods <-tibble(
  order = c(rep("a",12),
            rep("b",12),
            rep("c",12),
            rep("d",11)
  ),
  label = c(rep("1973-1984",12),
            rep("1985-1996",12),
            rep("1997-2008",12),
            rep("2009-2019",11)
  ),
  year = c(seq(1973,1984,1),
           seq(1985,1996,1),
           seq(1997,2008,1),
           seq(2009,2019,1)
  )
)


state_lat <- historic_spp %>%
  group_by(state) %>% 
  summarise(
    order = mean(lat)
  ) %>% 
  mutate(abrev = c("CT","DE","ME","MD","MA","NH","NJ","NY","NC","RI","VA")
  ) %>% 
  arrange(desc(order)) %>% 
  mutate(order= letters[1:11])



# State pallet

state_pallet <- c(wes_palette(n = 5, name = "Darjeeling1"),
                               wes_palette(n = 5, name = "Darjeeling2"),
                               # wes_palette(n = 2, name = "GrandBudapest1")
                  "#FD6467"
                  )



# print for notebook
head(historic_spp)
```

## Average proportion

This map shows the aggregated extrapolated value from all three species per State average across the whole study period within each State's water.

*Note:* This is intended to be a supplemental figure

```{r area_map_state, eval = T, echo = T, fig.width=10, fig.height=12}

 data_grid <- historic_spp %>% 
  group_by(state,lat,lon,region) %>% 
  summarise(sum = sum(value,na.rm= T), .groups = "drop") %>% # sum of all species
  group_by(state,lat,lon,region) %>% 
  summarise(mean = mean(sum,na.rm= T), .groups = "drop") # average of all years


ggplot(data = subset(data_grid, !is.na(mean))) +
  geom_tile(
    aes(
      x = lon,
      y = lat,
      fill = mean,
      col = mean
    )
  ) +
  geom_sf(data = land_sf, aes()) +
  facet_wrap(~ state  +  region,
             ncol = 4) +
  labs(x = "Longitude", y = "Latitude") +
  scale_fill_viridis("Mean Interpolation", alpha = 0.8) +
  scale_color_viridis("Mean Interpolation", alpha = 0.8) +
  theme_bw()
```

## Proportion Change

Here we show the average proportion of the interpolation by State and time period. Time periods were arbitrary defined as;

- Early; 1973 to 1984
- Mid; 1985 to 1997
- Late; 1998 to 2011
- Now; 2012 to 2019

*Notes:* Figure represents the **Spring** survey. This computation considers the Overlapping of state waters.

### Dynamic figure: Aggregated Proportional change per survey

```{r area_map_aggregated, eval = T, echo = T, fig.width = 10, fig.height=6}

total_fited <- historic_spp %>% 
  group_by(year,region) %>% 
  summarise(total_value = sum(value,na.rm=T),.groups = "drop")


state_fit <- historic_spp %>% 
  group_by(state,year,region) %>% 
  summarise(state_value = sum(value,na.rm= T), .groups = "drop") %>% 
  left_join(total_fited,
            by = c("year","region")) %>%
  mutate(percentage = state_value/total_value*100) %>% 
  left_join(periods,
            by = "year") %>% 
  group_by(state,order,label,region) %>% 
  summarise(mean_per = round(mean(percentage)),.groups = "drop")

# check percentages
# state_fit %>% 
#   group_by(period) %>% 
#   summarise(sum(mean_per))


p <- land_sf %>% 
  left_join(state_fit,
            by = "state") %>% 
  ggplot() +
  # geom_sf(aes(fill = mean_per)) +
  geom_sf(aes(fill = mean_per, text = paste(state, mean_per,"% of proportion"))) +
  viridis::scale_fill_viridis("Average proportion per State", alpha = 0.8) +
  facet_wrap(~ region + label, 
             nrow = 2) +
  labs(x = "Latitude", 
       y = "Longitude") +
  my_ggtheme_p(facet_tx_s = 12,
               leg_pos = "bottom") +
  theme(legend.key.width = unit(1,"line")) +
  theme_dark()

ggplotly(p,
         tooltip = "text",
         dynamicTicks = FALSE) %>% 
    style(hoverlabel = list(bgcolor = "white"), hoveron = "fill")


```


### Paper figure; Per species maps

```{r paper_figure_area_map, eval = F, echo = T, results='hide'}

total_fited <- historic_spp %>% 
  group_by(year,region,spp) %>% 
  summarise(total_value = sum(value,na.rm=T),.groups = "drop")


state_fit <- historic_spp %>% 
  group_by(state,year,region,spp) %>% 
  summarise(state_value = sum(value,na.rm= T), .groups = "drop") %>% 
  left_join(total_fited,
            by = c("year","region","spp")) %>%
  mutate(percentage = state_value/total_value*100) %>% 
  left_join(periods,
            by = "year") %>% 
  group_by(state,order,label,region,spp) %>% 
  summarise(mean_per = round(mean(percentage)),.groups = "drop") %>% 
  #Only show results for spring
  filter(str_detect(region,"Spring")) %>% 
  mutate(spp = gsub(" ","\n",spp))

# The plot
map_plot <- land_sf %>% 
  left_join(state_fit,
            by = "state") %>% 
  ggplot() +
  geom_sf(aes(fill = mean_per)) +
  viridis::scale_fill_viridis("Average proportion per State", alpha = 0.8) +
  facet_grid(spp ~ label) +
  labs(x = "Longitude", 
       y = "Latitude") +
  my_ggtheme_p(facet_tx_s = 20,
               leg_pos = "bottom",
               axx_tx_ang = 45,
               ax_tx_s = 12,
               ax_tl_s = 18,
               hjust = 1) +
  theme(legend.key.width = unit(4,"line")) 


  ggsave(filename = "proportion_chg_spp.jpg",
         plot = map_plot,
         path = my_path("R","Figures"),
         width = 14,
         height = 14
         )


```


![Proportion change per species map for paper](/Volumes/Enterprise/Data/AcrossBoundaries/Results/Figures/proportion_chg_spp.jpg)


### Paper figure: Aggregated Proportional change

```{r area_map_aggregated_formans, eval = T, echo = T, fig.width = 10, fig.height=6}

total_fited <- historic_spp %>% 
  group_by(year,region) %>% 
  summarise(total_value = sum(value,na.rm=T),.groups = "drop")


state_fit <- historic_spp %>% 
  group_by(state,year,region) %>% 
  summarise(state_value = sum(value,na.rm= T), .groups = "drop") %>% 
  left_join(total_fited,
            by = c("year","region")) %>%
  mutate(percentage = state_value/total_value*100) %>% 
  left_join(periods,
            by = "year") %>% 
  group_by(state,order,label,region) %>% 
  summarise(mean_per = round(mean(percentage)),.groups = "drop") %>% 
  filter(str_detect(region,"Spring"))


agg_map <- land_sf %>% 
  left_join(state_fit,
            by = "state") %>% 
  ggplot() +
  geom_sf(aes(fill = mean_per)) +
  viridis::scale_fill_viridis("Average proportion per State", alpha = 0.8) +
  facet_wrap(~ label, nrow = 1) +
  labs(x = "Longitude", 
       y = "Latitude") +
  my_ggtheme_p(facet_tx_s = 16,
               leg_pos = "bottom",
               leg_tl_s = 14,
               ax_tx_s = 10,
               ax_tl_s = 14) +
  theme(legend.key.width = unit(2,"line")) 

  ggsave(filename = "proportion_chg_agg.jpg",
         plot = agg_map,
         path = my_path("R","Figures"),
         width = 9,
         height = 5
         )

```

![Proportion change aggregated all species map for paper](/Volumes/Enterprise/Data/AcrossBoundaries/Results/Figures/proportion_chg_agg.jpg)


## Area plot

This graph shows the proportion of the interpolation value each State has over time.

*Note:* This plot is interactive. For ease comparison between States you can;

- *One* click on any State to *remove* it from the plot 
- *Two* clicks on any State to *isolate it* from the plot (other states can then be added by just clicking on them).
- The bottom panel allows you to reduce the time frame

### Dynamic aggregated plot

```{r dynamic_area_plot, eval = T, echo = T, fig.height = 10, fig.width = 10}

total_fited <- historic_spp %>% 
  group_by(year,region) %>% 
  summarise(total_value = sum(value,na.rm=T),.groups = "drop")

# group by state
state_fit <- historic_spp %>% 
  group_by(state,year,region) %>% 
  summarise(state_value = sum(value,na.rm= T), .groups = "drop") %>% 
  left_join(total_fited,
            by = c("year","region")) %>%
  mutate(percentage = state_value/total_value*100)

# Plot me
p <- ggplot(state_fit) +
  geom_area(
    aes(
      x = year,
      y = round(percentage),
      fill = state
    )
  ) +
  ylab("Percentage (%)") +
  # viridis::scale_fill_viridis(discrete = T, alpha = 0.8) +
  scale_fill_manual(values = state_pallet) +
  MyFunctions::my_ggtheme_p() +
  facet_wrap(~region, ncol = 1) +
  theme_dark()

ggplotly(p,
         dynamicTicks = TRUE) %>% 
  layout(hovermode = "x") %>%
  rangeslider()

```

## Area plot (running mean)

This graph shows the proportion of each State smoothed over a *10 years running mean**. It allows to better see increasing and decreasing trends.

### Dynamic aggregated plot

*Note:* This plot is also interactive and thus, follows the same options of the previous one.

```{r area_plot, eval = T, echo = T, fig.height = 10, fig.width = 10}

# group by state
state_fit <- historic_spp %>% 
  group_by(state,year,region,.groups = "drop") %>% 
  summarise(state_value = sum(value,na.rm= T), .groups = "drop") %>% 
  left_join(total_fited,
            by = c("year","region")) %>%
  mutate(percentage = state_value/total_value*100) %>% 
  group_by(state,region) %>% 
  mutate(RMean = zoo::rollmean(x = percentage, 
                            10,
                            fill = NA,
                            na.rm=T)
    ) %>%  
  left_join(state_lat)

# Plot me
p <- ggplot(state_fit) +
  geom_area(
    aes(
      x = year,
      y = round(RMean),
      fill = state
      # fill = order
    )
  ) +
  ylab("10 yrs running average (%)") +
  scale_fill_manual(
    "State",
    values = state_pallet,
    # labels = state_fit %>% arrange(order) %>%  pull(state) %>% unique()
  ) +
  MyFunctions::my_ggtheme_p() +
  facet_wrap(~region, ncol = 1) +
  theme_dark()

suppressWarnings(
ggplotly(p,
         dynamicTicks = TRUE) %>% 
  layout(hovermode = "x") %>% 
  # add_trace() %>% 
  rangeslider()
)

```

### Paper figure: Aggregated Proportional change

```{r plot_area_ave_agg, eval = F, echo = F, results='hide'}

total_fited <- historic_spp %>% 
  group_by(year,region) %>% 
  summarise(total_value = sum(value,na.rm=T),.groups = "drop")


# group by state
state_fit <- historic_spp %>% 
  group_by(state,year,region) %>% 
  summarise(state_value = sum(value,na.rm= T), .groups = "drop") %>% 
  left_join(total_fited,
            by = c("year","region")) %>%
  mutate(percentage = state_value/total_value*100) %>% 
  group_by(state,region) %>% 
  mutate(RMean = zoo::rollmean(x = percentage, 
                            10,
                            fill = NA,
                            na.rm=T)
    ) %>% 
  #Only show results for spring
  filter(str_detect(region,"Spring"),
         !is.na(RMean) # Remove NAs from rollmean
         ) %>%  
  left_join(state_lat)

# Plot me
agg_area <- ggplot(state_fit) +
  geom_area(
    aes(
      x = year,
      y = round(RMean),
      fill = order
      # fill = state
    )
  ) +
  ylab("Propotion (10 yrs running average)") +
  # viridis::scale_fill_viridis(discrete = T, alpha = 0.8) +
  scale_fill_manual(
    "State",
    values = state_pallet,
    labels = state_fit %>% arrange(order) %>%  pull(state) %>% unique()
  ) +
  my_ggtheme_p(leg_pos = "right") +
  theme(legend.key.width = unit(1,"line"))


  ggsave(filename = "area_plot_avg_agg.jpg",
         plot = agg_area,
         path = my_path("R","Figures"),
         width = 8,
         height = 6
  )


```

![Proportion change aggregated all species map for paper](/Volumes/Enterprise/Data/AcrossBoundaries/Results/Figures/area_plot_avg_agg.jpg)

### Paper figure: Per Species Proportional change

```{r paper_plot_area_ave_spp, eval = F, echo = F, results='hide'}

total_fited <- historic_spp %>% 
  group_by(year,region,spp) %>% 
  summarise(total_value = sum(value,na.rm=T),.groups = "drop")


# group by state
state_fit <- historic_spp %>% 
  group_by(state,year,region,spp) %>% 
  summarise(state_value = sum(value,na.rm= T), .groups = "drop") %>% 
  left_join(total_fited,
            by = c("year","region","spp")) %>%
  mutate(percentage = state_value/total_value*100) %>% 
  group_by(state,region,spp) %>% 
  mutate(RMean = zoo::rollmean(x = percentage, 
                            10,
                            fill = NA,
                            na.rm=T)
    ) %>% 
  #Only show results for spring
  filter(str_detect(region,"Spring"),
         !is.na(RMean) # Remove NAs from rollmean
         ) %>%  
  left_join(state_lat)

# Plot me
ssp_area <- ggplot(state_fit) +
  geom_area(
    aes(
      x = year,
      y = round(RMean),
      fill = order
      # fill = state
    )
  ) +
  ylab("Propotion (10 yrs running average)") +
  # viridis::scale_fill_viridis(discrete = T, alpha = 0.8) +
  scale_fill_manual(
    "State",
    values = state_pallet,
    labels = state_fit %>% arrange(order) %>%  pull(state) %>% unique()
  ) +
  my_ggtheme_p(leg_pos = "bottom") +
  theme(legend.key.width = unit(1,"line")) + 
  facet_wrap(~spp, ncol = 1, strip.position = "right")


  ggsave(filename = "area_plot_avg_spp.jpg",
         plot = ssp_area,
         path = my_path("R","Figures"),
         width = 10,
         height = 12
  )


```
![Proportion change aggregated all species map for paper](/Volumes/Enterprise/Data/AcrossBoundaries/Results/Figures/area_plot_avg_spp.jpg)

## Historic quota Vs distributions

This section of the results explores the differences between the historic distribution of te stock and the historic quota allocation. We collected the proportion of the total quota that each State gets for each species.

Right now the analysis only covers black sea bass, summer flounder and scup. But we can go speceis by species to see which ones have their quota allocated by state to include them in the analysis.

- [Black Sea Bass; *Centropristis striata*](https://www.mafmc.org/newsfeed/2021/asmfc-and-mafmc-approve-bsb-commercial-allocation-changes)

**Note:** We are using the new allocations based on the stock's most recent biomass distribution* 

- [Summer flounder](http://www.asmfc.org/uploads/file/5f9af82a2019SummerFlounderFMP_Review.pdf)

- [Scup](http://www.asmfc.org/uploads/file/5f99d0112019_Scup_FMP_Review_approved.pdf) Summer period

For State-level managed species see the [Atlantic States Marine Fisheries Comission](http://www.asmfc.org/fisheries-management/program-overview) website and go species-by-species.


```{r state_quota_tbl,eval= T, echo = T}

quota_allocation <- state_lat %>% 
  mutate(
    "Centropristis striata" = c(
      0.0040, #ME
      0.0040, #NH
      0.1564, #MA
      0.1323, #RI
      0.0367, #CT
      0.0857, #NY
      0.2010, #NJ
      0.0411, #DE
      0.0888, #MD
      0.1614, #VA
      0.0888 #NC
    ),
    "Paralichthys dentatus" = c(
      0.0004756, #ME 
      0.0000046, #NH 
      0.0682046, #MA 
      0.1568298, #RI 
      0.0225708, #CT 
      0.0764699, #NY 
      0.1672499, #NJ 
      0.0001779, #DE 
      0.0203910, #MD
      0.2131676, #VA
      0.2744584 #NC
    ),
    "Stenotomus chrysops" = c(
      0.0012101, #ME
      0.0000000, #HN
      0.2158729, #MA
      0.5619456, #RI
      0.0315399, #CT
      0.1582466, #NY
      0.0291667, #NJ
      0.0000000, #DE
      0.0001190, #MD
      0.0016502, #VA
      0.0002490 #NC
    )
  ) %>% 
  gather("spp","quota",4:6)

# Double check they all add to 1...
quota_allocation %>% 
  group_by(spp) %>% 
  summarise_at(vars(quota),sum)


quota_allocation %>% 
  arrange(order) %>% 
  select(-order) %>% 
  spread(spp,quota) %>% 
  kable()
```


### Get data ready

```{r}

total_fited <- historic_spp %>% 
  group_by(year,region,spp) %>% 
  summarise(total_value = sum(value,na.rm=T),.groups = "drop")

# group by state
state_fit <- historic_spp %>% 
  group_by(state,year,region,spp) %>% 
  summarise(state_value = sum(value,na.rm= T), .groups = "drop") %>% 
  left_join(total_fited,
            by = c("year","region","spp")) %>%
  mutate(percentage = state_value/total_value*100) %>% 
  #Only show results for spring
  filter(str_detect(region,"Spring"))

quota_df <- quota_allocation %>% 
  left_join(historic_spp) %>% 
  group_by(state,abrev,year,region,spp,quota) %>% 
  summarise(state_value = sum(value,na.rm= T), .groups = "drop") %>% 
  left_join(total_fited,
            by = c("year","region","spp")) %>%
  mutate(Distribution = state_value/total_value*100,
         Historic = quota*100) %>% 
  group_by(state,quota,spp) %>% 
  mutate(RMean = zoo::rollmean(x = Distribution, 
                            10,
                            fill = NA,
                            na.rm=T)
    ) %>% 
  #Only show results for spring
  filter(str_detect(region,"Spring"),
         !is.na(RMean) # Remove NAs from rollmean
         ) %>%  
  left_join(state_lat) %>% 
  filter(
    # spp =="Centropristis striata"
    spp %in% quota_allocation$spp
  )

head(quota_df) %>% 
  kable()
```

### Exploring different ways to show the results

#### Difference line plot

This version shows the difference between the Historic quota allocation and the distribution proportion of the stock:

- diff < 0 = the distribution proportion is *larger* than the allocated quota
- diff > 0 = the distribution proportion is *smaller* than the allocated quota 

```{r}
# Option one

quota_df %>%
  mutate(diff = Historic- Distribution,
         diff_rmean = RMean- Distribution) %>% 
  gather("type","value",diff:diff_rmean) %>% 
  # View()
  ggplot() +
  geom_line(
    aes(
      x = year,
      y = value,
      color = order
    )
  ) +
  scale_color_manual("State",
    values = state_pallet,
    labels = quota_df %>% arrange(order) %>%  pull(state) %>% unique()
    ) +
  facet_grid(type~spp, 
             scales = "free") +
  theme_dark()

```
#### Linetype plot

Here, we plot the distributional quota (solid lines) with each State's allocation with dashed (----) lines

```{r}
# Option one

quota_df %>% 
  gather("level","quota",Distribution:RMean) %>% 
  # mutate(diff = quota_per- percentage) %>% 
  # View()
  ggplot() +
  geom_line(
    aes(
      x = year,
      y = quota,
      color = order
    )
  ) +
  labs(x = "Year",y = "Quota (%)") +
  scale_fill_manual("State",
    values = state_pallet,
    labels = quota_df %>% arrange(order) %>%  pull(state) %>% unique()
    ) +
  scale_color_manual("State",
    values = state_pallet,
    labels = quota_df %>% arrange(order) %>%  pull(state) %>% unique()
    ) +
  scale_linetype("Quota") +
  facet_grid(spp ~ level)+
  theme_dark()

```
#### Efficiency index

The idea here is create and *efficiency index* (Danger!) that computes the alignment between the distribution and the actual allocation. The index is simply;

$$ei = \frac{HistoricQuota}{DistributionProportion}$$ 
So, in cases where *ei* = 1, the quota is aligned with the distribution; when *ei* > 1 then the historic quota is more than the stock's State's distribution, contrarily, *ei* < 1 means that the historic quota is less than what the State currently has.


**Note:** 
- There are some crazzy outliers that have been removed, for now... 
- Bottom plot representing index as a Rmean

##### As a normal year to year

```{r}
# Option one

eff_index <- quota_df %>% 
  # filter(
  #   spp =="Centropristis striata"
  # ) %>% 
  mutate(index = Distribution/Historic,
         index_rmean = RMean/Historic) %>%
  gather("level","index",index:index_rmean) %>%
  filter(index < 5) # there are some craaaazy outliers
  # View()
  
ggplot(eff_index) +
  geom_line(
    aes(
      x = year,
      y = index,
      color = state
    ),
  ) +
  labs(x = "Year",y = "Efficiency index") +
  scale_fill_manual("State",
    values = state_pallet,
    labels = quota_df %>% arrange(order) %>%  pull(state) %>% unique()
    ) +
  scale_color_manual("State",
    values = state_pallet,
    labels = quota_df %>% arrange(order) %>%  pull(state) %>% unique()
    ) +
  facet_grid(level~spp,
             scales = "free")+
  theme_dark()

```

